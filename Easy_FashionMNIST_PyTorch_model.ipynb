{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be6f9ccc",
   "metadata": {},
   "source": [
    "The code below is from the PyTorch documentation: https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "\n",
    "For each box below, in a question-awnser format, I will explain the code below.\n",
    "\n",
    "Publicar isto na secção de machine learning do IEEE NOVA SB\n",
    "\n",
    "dizer que a melhor forma de aprender PyTorch para min, foi ler até capitulo 10 de grooking deep learning e depois ler a documentação onde tirei o codigo em https://pytorch.org/tutorials/beginner/basics/intro.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a7cee7",
   "metadata": {},
   "source": [
    "dizer versões de cad um destes\n",
    "\n",
    "pip install --upgrade pip\n",
    "\n",
    "pip install virtualenv\n",
    "\n",
    "virtualenv envname\n",
    "\n",
    "source envname/bin/activate\n",
    "\n",
    "https://datagy.io/python-requirements-txt/\n",
    "\n",
    "https://pypi.org/project/torchvision/\n",
    "\n",
    "https://pypi.org/project/torch/\n",
    "\n",
    "https://pypi.org/project/jupyter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27aba5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc0d4e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a53d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0091cfdd",
   "metadata": {},
   "source": [
    "#### What is batch_size?\n",
    "\n",
    "\n",
    "#### What the DataLoader function does in simple terms?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da935282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e70e67f",
   "metadata": {},
   "source": [
    "#### what super.__init__() does?\n",
    "\n",
    "#### what nn.Flatten() does?\n",
    "\n",
    "#### what the nn.linear() function does and how can I visualize, in a neural network, what is happening in nn.sequencial?\n",
    "\n",
    "ver isto https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44fe9a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8162dbe",
   "metadata": {},
   "source": [
    "#### What nn.CrossEntropyLoss() does?\n",
    "\n",
    "#### what torch.optim.SGD(model.parameters(), lr=1e-3) does?\n",
    "\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46576df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2378c342",
   "metadata": {},
   "source": [
    "#### Why len(dataloader.dataset) works?\n",
    "\n",
    "###### faltam mais questoes a colocar aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ac63220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0a3ed8",
   "metadata": {},
   "source": [
    "###### faltam mais questoes a colocar aqui\n",
    "\n",
    "How to save a model?\n",
    "https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19b5975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.300461  [    0/60000]\n",
      "loss: 2.285733  [ 6400/60000]\n",
      "loss: 2.267792  [12800/60000]\n",
      "loss: 2.266686  [19200/60000]\n",
      "loss: 2.253236  [25600/60000]\n",
      "loss: 2.219331  [32000/60000]\n",
      "loss: 2.231474  [38400/60000]\n",
      "loss: 2.197506  [44800/60000]\n",
      "loss: 2.192284  [51200/60000]\n",
      "loss: 2.162463  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 49.3%, Avg loss: 2.153005 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.157935  [    0/60000]\n",
      "loss: 2.144171  [ 6400/60000]\n",
      "loss: 2.088566  [12800/60000]\n",
      "loss: 2.112419  [19200/60000]\n",
      "loss: 2.055699  [25600/60000]\n",
      "loss: 1.991251  [32000/60000]\n",
      "loss: 2.026921  [38400/60000]\n",
      "loss: 1.945186  [44800/60000]\n",
      "loss: 1.951559  [51200/60000]\n",
      "loss: 1.877677  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.2%, Avg loss: 1.874058 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.902230  [    0/60000]\n",
      "loss: 1.869534  [ 6400/60000]\n",
      "loss: 1.752790  [12800/60000]\n",
      "loss: 1.803331  [19200/60000]\n",
      "loss: 1.688113  [25600/60000]\n",
      "loss: 1.629922  [32000/60000]\n",
      "loss: 1.663952  [38400/60000]\n",
      "loss: 1.562655  [44800/60000]\n",
      "loss: 1.588473  [51200/60000]\n",
      "loss: 1.480236  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 1.498892 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.563935  [    0/60000]\n",
      "loss: 1.528472  [ 6400/60000]\n",
      "loss: 1.376958  [12800/60000]\n",
      "loss: 1.458647  [19200/60000]\n",
      "loss: 1.335938  [25600/60000]\n",
      "loss: 1.324809  [32000/60000]\n",
      "loss: 1.350201  [38400/60000]\n",
      "loss: 1.274835  [44800/60000]\n",
      "loss: 1.309234  [51200/60000]\n",
      "loss: 1.210076  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.235089 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.310345  [    0/60000]\n",
      "loss: 1.293212  [ 6400/60000]\n",
      "loss: 1.125458  [12800/60000]\n",
      "loss: 1.240149  [19200/60000]\n",
      "loss: 1.110576  [25600/60000]\n",
      "loss: 1.130165  [32000/60000]\n",
      "loss: 1.162056  [38400/60000]\n",
      "loss: 1.099902  [44800/60000]\n",
      "loss: 1.137961  [51200/60000]\n",
      "loss: 1.055798  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 1.075115 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.142794  [    0/60000]\n",
      "loss: 1.147307  [ 6400/60000]\n",
      "loss: 0.963276  [12800/60000]\n",
      "loss: 1.105752  [19200/60000]\n",
      "loss: 0.974817  [25600/60000]\n",
      "loss: 1.000442  [32000/60000]\n",
      "loss: 1.046672  [38400/60000]\n",
      "loss: 0.988882  [44800/60000]\n",
      "loss: 1.027867  [51200/60000]\n",
      "loss: 0.960468  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 0.973005 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.026869  [    0/60000]\n",
      "loss: 1.053524  [ 6400/60000]\n",
      "loss: 0.853071  [12800/60000]\n",
      "loss: 1.017200  [19200/60000]\n",
      "loss: 0.890047  [25600/60000]\n",
      "loss: 0.909288  [32000/60000]\n",
      "loss: 0.971381  [38400/60000]\n",
      "loss: 0.916382  [44800/60000]\n",
      "loss: 0.952458  [51200/60000]\n",
      "loss: 0.896959  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.9%, Avg loss: 0.903520 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.941632  [    0/60000]\n",
      "loss: 0.988348  [ 6400/60000]\n",
      "loss: 0.774082  [12800/60000]\n",
      "loss: 0.954434  [19200/60000]\n",
      "loss: 0.833088  [25600/60000]\n",
      "loss: 0.842322  [32000/60000]\n",
      "loss: 0.917998  [38400/60000]\n",
      "loss: 0.867352  [44800/60000]\n",
      "loss: 0.898043  [51200/60000]\n",
      "loss: 0.851262  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.853265 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.876086  [    0/60000]\n",
      "loss: 0.939185  [ 6400/60000]\n",
      "loss: 0.714619  [12800/60000]\n",
      "loss: 0.907483  [19200/60000]\n",
      "loss: 0.791982  [25600/60000]\n",
      "loss: 0.791910  [32000/60000]\n",
      "loss: 0.877377  [38400/60000]\n",
      "loss: 0.832920  [44800/60000]\n",
      "loss: 0.857224  [51200/60000]\n",
      "loss: 0.816191  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.814991 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.823554  [    0/60000]\n",
      "loss: 0.899301  [ 6400/60000]\n",
      "loss: 0.667999  [12800/60000]\n",
      "loss: 0.870985  [19200/60000]\n",
      "loss: 0.760345  [25600/60000]\n",
      "loss: 0.752984  [32000/60000]\n",
      "loss: 0.844484  [38400/60000]\n",
      "loss: 0.807396  [44800/60000]\n",
      "loss: 0.825373  [51200/60000]\n",
      "loss: 0.787943  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 0.784331 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.780150  [    0/60000]\n",
      "loss: 0.864935  [ 6400/60000]\n",
      "loss: 0.630195  [12800/60000]\n",
      "loss: 0.841795  [19200/60000]\n",
      "loss: 0.734632  [25600/60000]\n",
      "loss: 0.722143  [32000/60000]\n",
      "loss: 0.816438  [38400/60000]\n",
      "loss: 0.787318  [44800/60000]\n",
      "loss: 0.799359  [51200/60000]\n",
      "loss: 0.763993  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.758698 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.743044  [    0/60000]\n",
      "loss: 0.834453  [ 6400/60000]\n",
      "loss: 0.598581  [12800/60000]\n",
      "loss: 0.817497  [19200/60000]\n",
      "loss: 0.713209  [25600/60000]\n",
      "loss: 0.697077  [32000/60000]\n",
      "loss: 0.791524  [38400/60000]\n",
      "loss: 0.770457  [44800/60000]\n",
      "loss: 0.777435  [51200/60000]\n",
      "loss: 0.743126  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.736484 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.710593  [    0/60000]\n",
      "loss: 0.806800  [ 6400/60000]\n",
      "loss: 0.571717  [12800/60000]\n",
      "loss: 0.796715  [19200/60000]\n",
      "loss: 0.694789  [25600/60000]\n",
      "loss: 0.676387  [32000/60000]\n",
      "loss: 0.768777  [38400/60000]\n",
      "loss: 0.755679  [44800/60000]\n",
      "loss: 0.758435  [51200/60000]\n",
      "loss: 0.724631  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 0.716716 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.681960  [    0/60000]\n",
      "loss: 0.781447  [ 6400/60000]\n",
      "loss: 0.548357  [12800/60000]\n",
      "loss: 0.778561  [19200/60000]\n",
      "loss: 0.678695  [25600/60000]\n",
      "loss: 0.659020  [32000/60000]\n",
      "loss: 0.747597  [38400/60000]\n",
      "loss: 0.742324  [44800/60000]\n",
      "loss: 0.741657  [51200/60000]\n",
      "loss: 0.707664  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.698824 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.656377  [    0/60000]\n",
      "loss: 0.758066  [ 6400/60000]\n",
      "loss: 0.527806  [12800/60000]\n",
      "loss: 0.762361  [19200/60000]\n",
      "loss: 0.664648  [25600/60000]\n",
      "loss: 0.644039  [32000/60000]\n",
      "loss: 0.727828  [38400/60000]\n",
      "loss: 0.730138  [44800/60000]\n",
      "loss: 0.726740  [51200/60000]\n",
      "loss: 0.692040  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.682453 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.633319  [    0/60000]\n",
      "loss: 0.736511  [ 6400/60000]\n",
      "loss: 0.509606  [12800/60000]\n",
      "loss: 0.747590  [19200/60000]\n",
      "loss: 0.652304  [25600/60000]\n",
      "loss: 0.630993  [32000/60000]\n",
      "loss: 0.709437  [38400/60000]\n",
      "loss: 0.719103  [44800/60000]\n",
      "loss: 0.713506  [51200/60000]\n",
      "loss: 0.677546  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.667402 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.612356  [    0/60000]\n",
      "loss: 0.716674  [ 6400/60000]\n",
      "loss: 0.493408  [12800/60000]\n",
      "loss: 0.733924  [19200/60000]\n",
      "loss: 0.641364  [25600/60000]\n",
      "loss: 0.619527  [32000/60000]\n",
      "loss: 0.692190  [38400/60000]\n",
      "loss: 0.709223  [44800/60000]\n",
      "loss: 0.701927  [51200/60000]\n",
      "loss: 0.664075  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.653539 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.593359  [    0/60000]\n",
      "loss: 0.698544  [ 6400/60000]\n",
      "loss: 0.478787  [12800/60000]\n",
      "loss: 0.721234  [19200/60000]\n",
      "loss: 0.631795  [25600/60000]\n",
      "loss: 0.609427  [32000/60000]\n",
      "loss: 0.676023  [38400/60000]\n",
      "loss: 0.700548  [44800/60000]\n",
      "loss: 0.691807  [51200/60000]\n",
      "loss: 0.651558  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.640761 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.576175  [    0/60000]\n",
      "loss: 0.681895  [ 6400/60000]\n",
      "loss: 0.465554  [12800/60000]\n",
      "loss: 0.709515  [19200/60000]\n",
      "loss: 0.623230  [25600/60000]\n",
      "loss: 0.600566  [32000/60000]\n",
      "loss: 0.660862  [38400/60000]\n",
      "loss: 0.693067  [44800/60000]\n",
      "loss: 0.683049  [51200/60000]\n",
      "loss: 0.639812  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.628979 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.560394  [    0/60000]\n",
      "loss: 0.666713  [ 6400/60000]\n",
      "loss: 0.453608  [12800/60000]\n",
      "loss: 0.698476  [19200/60000]\n",
      "loss: 0.615561  [25600/60000]\n",
      "loss: 0.592629  [32000/60000]\n",
      "loss: 0.646776  [38400/60000]\n",
      "loss: 0.686599  [44800/60000]\n",
      "loss: 0.675530  [51200/60000]\n",
      "loss: 0.628706  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.618122 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65ecebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### faltam mais questoes a colocar aqui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
